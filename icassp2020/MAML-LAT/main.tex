% Template for ICASSP-2020 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
%\usepackage{multicol}
%\usepackage{multirow}
\documentclass{article}
\usepackage{color}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{spconf,amsmath,graphicx}
\usepackage{siunitx}
\usepackage{tikz}
\usepackage{pgfplotstable}
\usepackage{subfig}
\usepackage{float}
%\usepackage[preprint]{spconf}
\usepackage[OT1]{fontenc} % TODO: 之後放到 overleaf 要移掉！！

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}
\pgfplotsset{compat=1.16}

% ------
\title{Meta Learning for End-to-End Low-Resource Speech Recognition}
%
% Single address.
% ---------------
%\name{Jui-Yang Hsu, Yuan-Jui Chen,  Hung-yi Lee}
\name{Jui-Yang Hsu\qquad Yuan-Jui Chen\qquad  Hung-yi Lee}
\address{National Taiwan University \\
\small{\texttt{\{r07921053, r07922070, hungyilee\}@ntu.edu.tw}}}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
 (HAVEN'T FINISHED YET)  Besides directly training the model with all the source languages, there are various variants of MultiASR approaches. 
Language-adversarial training approaches \cite{Yi2018AdversarialMT, adams2019massively} introduce language-adversarial classification objective to the shared encoder, negating the gradients backpropagated from the language classifier to encourage the encoder to extract more language-independent representations. 
Hierarchical approaches \cite{Sanabria2018HierarchicalMT} introduce different granularity objectives by combining both character and phoneme prediction at different levels of the model.
In addition, based on MAML's model-agnostic property, this approach can be applied to other network architecture like Seq2seq model, and even different applications other than speech recognition in the speech community.
\end{abstract}
%
\begin{keywords}
  meta-learning, low-resource, speech recognition, language adaptation, IARPA-BABEL
\end{keywords}
%
\input{intro.tex}
\input{approach.tex}
\input{exp.tex}
\input{result.tex}
%\input{figs/impact_on_size.tex}

\section{Conclusion}
\label{sec:conclusion}
(HAVEN'T FINISHED YET) In this paper, we proposed the meta learning approach to multilingual pretraining for speech recognition. The initial experimental results showed its potential in pretraining. In future work, We plan to use more languages (from IARPA BABEL or other corpora) and different combinations for pretraining to evaluate the effectiveness of MetaASR more extensively. 

In addition, based on MAML's model-agnostic property, this approach can be applied to other network architecture like Seq2seq model, and even different applications other than speech recognition in the speech community.

% Below is an example of how to insert images. Delete the ``\vspace'' line,
% uncomment the preceding line ``\centerline...'' and replace ``imageX.ps''
% with a suitable PostScript file name.
% -------------------------------------------------------------------------


% To start a new column (but not a new page) and help balance the last-page
% column length use \vfill\pagebreak.
% -------------------------------------------------------------------------
%\vfill
%\pagebreak


%\section{REFERENCES}
% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\newpage
\bibliography{strings,refs}

% 以下不會放到 paper ，只是畫一些圖出來而已
%\newpage
\section{Appendix (WON'T PUT ON PAPER)}

\newpage
% NEAR3
\begin{section}{Near 3}
\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi3-vietnamese};
  \addplot+[smooth]table{meta-stat/meta3-vietnamese};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Vietnamese's LLP (near3)}
\end{figure}

\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi3-swahili};
  \addplot+[smooth]table{meta-stat/meta3-swahili};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Swahili's LLP (near3)}
\end{figure}

\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi3-tamil};
  \addplot+[smooth]table{meta-stat/meta3-tamil};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Tamil's LLP (near3)}
\end{figure}

\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi3-kurmanji};
  \addplot+[smooth]table{meta-stat/meta3-kurmanji};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Kurmanji's LLP (near3)}
\end{figure}

\end{section}
\newpage
%% NEAR 6
\begin{section}{Near 6}
\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi6-vietnamese};
  \addplot+[smooth]table{meta-stat/meta6-vietnamese};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Vietnamese's LLP (near6)}
\end{figure}

\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi6-swahili};
  \addplot+[smooth]table{meta-stat/meta6-swahili};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Swahili's LLP (near6)}
\end{figure}

\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi6-tamil};
  \addplot+[smooth]table{meta-stat/meta6-tamil};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Tamil's LLP (near6)}
\end{figure}

\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/multi6-kurmanji};
  \addplot+[smooth]table{meta-stat/meta6-kurmanji};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Kurmanji's LLP (near6)}
\end{figure}
\end{section}

\newpage
\begin{section}{Other 3}
\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/other3-vietnamese};
  \addplot+[smooth]table{meta-stat/other3-vietnamese};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Vietnamese's LLP (other3)}
\end{figure}


\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/other3-swahili};
  \addplot+[smooth]table{meta-stat/other3-swahili};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Swahili's LLP (other3)}
\end{figure}


\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/other3-Tamil};
  \addplot+[smooth]table{meta-stat/other3-tamil};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Tamil's LLP (other3)}
\end{figure}


\begin{figure}[htb]
  \centering
  %\hspace{-2.2cm}
  \begin{tikzpicture}[trim axis left, trim axis right]

  \begin{axis}[
    width=\linewidth,
    height=6.5cm,
    legend entries={MultiASR, MetaASR} ,
    xlabel = {Number of pretraining steps ($\times 1000$)},
        xmin=5,
        %xmax=130,
        grid=both,
        legend style={at={(0.,.6)},anchor=south west},
        %legend pos=inner north west,
        ylabel={CER (\si{\percent}})]
  \addplot+[smooth]table{multi-stat/other3-kurmanji};
  \addplot+[smooth]table{meta-stat/other3-kurmanji};
   %\addplot[style=ultra thick,dashed,] coordinates {(0,0.557) (200,0.557)};
   %\addplot[style=ultra thick,dashed, gray] coordinates {(0,0.589) (200,0.589)};
   %\addplot[style=ultra thick,dashed, brown] coordinates {(0,0.628) (200,0.628)};
  \end{axis}
  \end{tikzpicture}
  %\caption{Pretrain on EN, FI, FR, NL, RM, RU, and evaluate on }
  \caption{The learning curves of CER on Kurmanji's LLP (other3)}
\end{figure}
\end{section}
\end{document}
